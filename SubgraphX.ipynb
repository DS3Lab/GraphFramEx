{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0007c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.special import comb\n",
    "from itertools import combinations\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.data import Data, Batch, Dataset, DataLoader\n",
    "\n",
    "\n",
    "def GnnNetsGC2valueFunc(gnnNets, target_class):\n",
    "    def value_func(batch):\n",
    "        with torch.no_grad():\n",
    "            logits = gnnNets(data=batch)\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            score = probs[:, target_class]\n",
    "        return score\n",
    "    return value_func\n",
    "\n",
    "\n",
    "def GnnNetsNC2valueFunc(gnnNets_NC, node_idx, target_class):\n",
    "    def value_func(data):\n",
    "        with torch.no_grad():\n",
    "            probs = gnnNets_NC(data.x, data.edge_index)\n",
    "            # select the corresponding node prob through the node idx on all the sampling graphs\n",
    "            batch_size = data.batch.max() + 1\n",
    "            probs = probs.reshape(batch_size, -1, probs.shape[-1])\n",
    "            score = probs[:, node_idx, target_class]\n",
    "            return score\n",
    "    return value_func\n",
    "\n",
    "\n",
    "def get_graph_build_func(build_method):\n",
    "    if build_method.lower() == 'zero_filling':\n",
    "        return graph_build_zero_filling\n",
    "    elif build_method.lower() == 'split':\n",
    "        return graph_build_split\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class MarginalSubgraphDataset(Dataset):\n",
    "    def __init__(self, data, exclude_mask, include_mask, subgraph_build_func):\n",
    "        self.num_nodes = data.num_nodes\n",
    "        self.X = data.x\n",
    "        self.edge_index = data.edge_index\n",
    "        self.device = self.X.device\n",
    "\n",
    "        self.label = data.y\n",
    "        self.exclude_mask = torch.tensor(exclude_mask).type(torch.float32).to(self.device)\n",
    "        self.include_mask = torch.tensor(include_mask).type(torch.float32).to(self.device)\n",
    "        self.subgraph_build_func = subgraph_build_func\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.exclude_mask.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        exclude_graph_X, exclude_graph_edge_index = self.subgraph_build_func(self.X, self.edge_index, self.exclude_mask[idx])\n",
    "        include_graph_X, include_graph_edge_index = self.subgraph_build_func(self.X, self.edge_index, self.include_mask[idx])\n",
    "        exclude_data = Data(x=exclude_graph_X, edge_index=exclude_graph_edge_index)\n",
    "        include_data = Data(x=include_graph_X, edge_index=include_graph_edge_index)\n",
    "        return exclude_data, include_data\n",
    "\n",
    "\n",
    "def marginal_contribution(data: Data, exclude_mask: np.array, include_mask: np.array,\n",
    "                          value_func, subgraph_build_func):\n",
    "    \"\"\" Calculate the marginal value for each pair. Here exclude_mask and include_mask are node mask. \"\"\"\n",
    "    marginal_subgraph_dataset = MarginalSubgraphDataset(data, exclude_mask, include_mask, subgraph_build_func)\n",
    "    dataloader = DataLoader(marginal_subgraph_dataset, batch_size=256, shuffle=False, num_workers=0)\n",
    "\n",
    "    marginal_contribution_list = []\n",
    "\n",
    "    for exclude_data, include_data in dataloader:\n",
    "        exclude_values = value_func(exclude_data)\n",
    "        include_values = value_func(include_data)\n",
    "        margin_values = include_values - exclude_values\n",
    "        marginal_contribution_list.append(margin_values)\n",
    "\n",
    "    marginal_contributions = torch.cat(marginal_contribution_list, dim=0)\n",
    "    return marginal_contributions\n",
    "\n",
    "\n",
    "def graph_build_zero_filling(X, edge_index, node_mask: np.array):\n",
    "    \"\"\" subgraph building through masking the unselected nodes with zero features \"\"\"\n",
    "    ret_X = X * node_mask.unsqueeze(1)\n",
    "    return ret_X, edge_index\n",
    "\n",
    "\n",
    "def graph_build_split(X, edge_index, node_mask: np.array):\n",
    "    \"\"\" subgraph building through spliting the selected nodes from the original graph \"\"\"\n",
    "    ret_X = X\n",
    "    row, col = edge_index\n",
    "    edge_mask = (node_mask[row] == 1) & (node_mask[col] == 1)\n",
    "    ret_edge_index = edge_index[:, edge_mask]\n",
    "    return ret_X, ret_edge_index\n",
    "\n",
    "\n",
    "def l_shapley(coalition: list, data: Data, local_radius: int,\n",
    "              value_func: str, subgraph_building_method='zero_filling'):\n",
    "    \"\"\" shapley value where players are local neighbor nodes \"\"\"\n",
    "    graph = to_networkx(data)\n",
    "    num_nodes = graph.number_of_nodes()\n",
    "    subgraph_build_func = get_graph_build_func(subgraph_building_method)\n",
    "\n",
    "    local_region = copy.copy(coalition)\n",
    "    for k in range(local_radius - 1):\n",
    "        k_neiborhoood = []\n",
    "        for node in local_region:\n",
    "            k_neiborhoood += list(graph.neighbors(node))\n",
    "        local_region += k_neiborhoood\n",
    "        local_region = list(set(local_region))\n",
    "\n",
    "    set_exclude_masks = []\n",
    "    set_include_masks = []\n",
    "    nodes_around = [node for node in local_region if node not in coalition]\n",
    "    num_nodes_around = len(nodes_around)\n",
    "\n",
    "    for subset_len in range(0, num_nodes_around + 1):\n",
    "        node_exclude_subsets = combinations(nodes_around, subset_len)\n",
    "        for node_exclude_subset in node_exclude_subsets:\n",
    "            set_exclude_mask = np.ones(num_nodes)\n",
    "            set_exclude_mask[local_region] = 0.0\n",
    "            if node_exclude_subset:\n",
    "                set_exclude_mask[list(node_exclude_subset)] = 1.0\n",
    "            set_include_mask = set_exclude_mask.copy()\n",
    "            set_include_mask[coalition] = 1.0\n",
    "\n",
    "            set_exclude_masks.append(set_exclude_mask)\n",
    "            set_include_masks.append(set_include_mask)\n",
    "\n",
    "    exclude_mask = np.stack(set_exclude_masks, axis=0)\n",
    "    include_mask = np.stack(set_include_masks, axis=0)\n",
    "    num_players = len(nodes_around) + 1\n",
    "    num_player_in_set = num_players - 1 + len(coalition) - (1 - exclude_mask).sum(axis=1)\n",
    "    p = num_players\n",
    "    S = num_player_in_set\n",
    "    coeffs = torch.tensor(1.0 / comb(p, S) / (p - S + 1e-6))\n",
    "\n",
    "    marginal_contributions = \\\n",
    "        marginal_contribution(data, exclude_mask, include_mask, value_func, subgraph_build_func)\n",
    "\n",
    "    l_shapley_value = (marginal_contributions.squeeze().cpu() * coeffs).sum().item()\n",
    "    return l_shapley_value\n",
    "\n",
    "\n",
    "def mc_shapley(coalition: list, data: Data,\n",
    "               value_func: str, subgraph_building_method='zero_filling',\n",
    "               sample_num=1000) -> float:\n",
    "    \"\"\" monte carlo sampling approximation of the shapley value \"\"\"\n",
    "    subset_build_func = get_graph_build_func(subgraph_building_method)\n",
    "\n",
    "    num_nodes = data.num_nodes\n",
    "    node_indices = np.arange(num_nodes)\n",
    "    coalition_placeholder = num_nodes\n",
    "    set_exclude_masks = []\n",
    "    set_include_masks = []\n",
    "\n",
    "    for example_idx in range(sample_num):\n",
    "        subset_nodes_from = [node for node in node_indices if node not in coalition]\n",
    "        random_nodes_permutation = np.array(subset_nodes_from + [coalition_placeholder])\n",
    "        random_nodes_permutation = np.random.permutation(random_nodes_permutation)\n",
    "        split_idx = np.where(random_nodes_permutation == coalition_placeholder)[0][0]\n",
    "        selected_nodes = random_nodes_permutation[:split_idx]\n",
    "        set_exclude_mask = np.zeros(num_nodes)\n",
    "        set_exclude_mask[selected_nodes] = 1.0\n",
    "        set_include_mask = set_exclude_mask.copy()\n",
    "        set_include_mask[coalition] = 1.0\n",
    "\n",
    "        set_exclude_masks.append(set_exclude_mask)\n",
    "        set_include_masks.append(set_include_mask)\n",
    "\n",
    "    exclude_mask = np.stack(set_exclude_masks, axis=0)\n",
    "    include_mask = np.stack(set_include_masks, axis=0)\n",
    "    marginal_contributions = marginal_contribution(data, exclude_mask, include_mask, value_func, subset_build_func)\n",
    "    mc_shapley_value = marginal_contributions.mean().item()\n",
    "\n",
    "    return mc_shapley_value\n",
    "\n",
    "\n",
    "def mc_l_shapley(coalition: list, data: Data, local_radius: int,\n",
    "                 value_func: str, subgraph_building_method='zero_filling',\n",
    "                 sample_num=1000) -> float:\n",
    "    \"\"\" monte carlo sampling approximation of the l_shapley value \"\"\"\n",
    "    graph = to_networkx(data)\n",
    "    num_nodes = graph.number_of_nodes()\n",
    "    subgraph_build_func = get_graph_build_func(subgraph_building_method)\n",
    "\n",
    "    local_region = copy.copy(coalition)\n",
    "    for k in range(local_radius - 1):\n",
    "        k_neiborhoood = []\n",
    "        for node in local_region:\n",
    "            k_neiborhoood += list(graph.neighbors(node))\n",
    "        local_region += k_neiborhoood\n",
    "        local_region = list(set(local_region))\n",
    "\n",
    "    coalition_placeholder = num_nodes\n",
    "    set_exclude_masks = []\n",
    "    set_include_masks = []\n",
    "    for example_idx in range(sample_num):\n",
    "        subset_nodes_from = [node for node in local_region if node not in coalition]\n",
    "        random_nodes_permutation = np.array(subset_nodes_from + [coalition_placeholder])\n",
    "        random_nodes_permutation = np.random.permutation(random_nodes_permutation)\n",
    "        split_idx = np.where(random_nodes_permutation == coalition_placeholder)[0][0]\n",
    "        selected_nodes = random_nodes_permutation[:split_idx]\n",
    "        set_exclude_mask = np.ones(num_nodes)\n",
    "        set_exclude_mask[local_region] = 0.0\n",
    "        set_exclude_mask[selected_nodes] = 1.0\n",
    "        set_include_mask = set_exclude_mask.copy()\n",
    "        set_include_mask[coalition] = 1.0\n",
    "\n",
    "        set_exclude_masks.append(set_exclude_mask)\n",
    "        set_include_masks.append(set_include_mask)\n",
    "\n",
    "    exclude_mask = np.stack(set_exclude_masks, axis=0)\n",
    "    include_mask = np.stack(set_include_masks, axis=0)\n",
    "    marginal_contributions = \\\n",
    "        marginal_contribution(data, exclude_mask, include_mask, value_func, subgraph_build_func)\n",
    "\n",
    "    mc_l_shapley_value = (marginal_contributions).mean().item()\n",
    "    return mc_l_shapley_value\n",
    "\n",
    "\n",
    "def gnn_score(coalition: list, data: Data, value_func: str,\n",
    "              subgraph_building_method='zero_filling') -> torch.Tensor:\n",
    "    \"\"\" the value of subgraph with selected nodes \"\"\"\n",
    "    num_nodes = data.num_nodes\n",
    "    subgraph_build_func = get_graph_build_func(subgraph_building_method)\n",
    "    mask = torch.zeros(num_nodes).type(torch.float32).to(data.x.device)\n",
    "    mask[coalition] = 1.0\n",
    "    ret_x, ret_edge_index = subgraph_build_func(data.x, data.edge_index, mask)\n",
    "    mask_data = Data(x=ret_x, edge_index=ret_edge_index)\n",
    "    mask_data = Batch.from_data_list([mask_data])\n",
    "    score = value_func(mask_data)\n",
    "    # get the score of predicted class for graph or specific node idx\n",
    "    return score.item()\n",
    "\n",
    "\n",
    "def NC_mc_l_shapley(coalition: list, data: Data, local_radius: int,\n",
    "                    value_func: str, node_idx: int = -1,\n",
    "                    subgraph_building_method='zero_filling', sample_num=1000) -> float:\n",
    "    \"\"\" monte carlo approximation of l_shapley where the target node is kept in both subgraph \"\"\"\n",
    "    graph = to_networkx(data)\n",
    "    num_nodes = graph.number_of_nodes()\n",
    "    subgraph_build_func = get_graph_build_func(subgraph_building_method)\n",
    "\n",
    "    local_region = copy.copy(coalition)\n",
    "    for k in range(local_radius - 1):\n",
    "        k_neiborhoood = []\n",
    "        for node in local_region:\n",
    "            k_neiborhoood += list(graph.neighbors(node))\n",
    "        local_region += k_neiborhoood\n",
    "        local_region = list(set(local_region))\n",
    "\n",
    "    coalition_placeholder = num_nodes\n",
    "    set_exclude_masks = []\n",
    "    set_include_masks = []\n",
    "    for example_idx in range(sample_num):\n",
    "        subset_nodes_from = [node for node in local_region if node not in coalition]\n",
    "        random_nodes_permutation = np.array(subset_nodes_from + [coalition_placeholder])\n",
    "        random_nodes_permutation = np.random.permutation(random_nodes_permutation)\n",
    "        split_idx = np.where(random_nodes_permutation == coalition_placeholder)[0][0]\n",
    "        selected_nodes = random_nodes_permutation[:split_idx]\n",
    "        set_exclude_mask = np.ones(num_nodes)\n",
    "        set_exclude_mask[local_region] = 0.0\n",
    "        set_exclude_mask[selected_nodes] = 1.0\n",
    "        if node_idx != -1:\n",
    "            set_exclude_mask[node_idx] = 1.0\n",
    "        set_include_mask = set_exclude_mask.copy()\n",
    "        set_include_mask[coalition] = 1.0  # include the node_idx\n",
    "\n",
    "        set_exclude_masks.append(set_exclude_mask)\n",
    "        set_include_masks.append(set_include_mask)\n",
    "\n",
    "    exclude_mask = np.stack(set_exclude_masks, axis=0)\n",
    "    include_mask = np.stack(set_include_masks, axis=0)\n",
    "    marginal_contributions = \\\n",
    "        marginal_contribution(data, exclude_mask, include_mask, value_func, subgraph_build_func)\n",
    "\n",
    "    mc_l_shapley_value = (marginal_contributions).mean().item()\n",
    "    return mc_l_shapley_value\n",
    "\n",
    "\n",
    "def sparsity(coalition: list, data: Data, subgraph_building_method='zero_filling'):\n",
    "    if subgraph_building_method == 'zero_filling':\n",
    "        return 1.0 - len(coalition) / data.num_nodes\n",
    "\n",
    "    elif subgraph_building_method == 'split':\n",
    "        row, col = data.edge_index\n",
    "        node_mask = torch.zeros(data.x.shape[0])\n",
    "        node_mask[coalition] = 1.0\n",
    "        edge_mask = (node_mask[row] == 1) & (node_mask[col] == 1)\n",
    "        return 1.0 - edge_mask.sum() / edge_mask.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ee08b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import copy\n",
    "import torch\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from torch import Tensor\n",
    "from textwrap import wrap\n",
    "from functools import partial\n",
    "from collections import Counter\n",
    "from typing import List, Tuple, Dict\n",
    "from torch_geometric.data import Batch, Data\n",
    "from torch_geometric.utils import to_networkx\n",
    "from typing import Callable, Union, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.utils.num_nodes import maybe_num_nodes\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.datasets import MoleculeNet\n",
    "from torch_geometric.utils import remove_self_loops\n",
    "\n",
    "\n",
    "def find_closest_node_result(results, max_nodes):\n",
    "    \"\"\" return the highest reward tree_node with its subgraph is smaller than max_nodes \"\"\"\n",
    "    results = sorted(results, key=lambda x: len(x.coalition))\n",
    "\n",
    "    result_node = results[0]\n",
    "    for result_idx in range(len(results)):\n",
    "        x = results[result_idx]\n",
    "        if len(x.coalition) <= max_nodes and x.P > result_node.P:\n",
    "            result_node = x\n",
    "    return result_node\n",
    "\n",
    "\n",
    "def reward_func(reward_method, value_func, node_idx=None,\n",
    "                local_radius=4, sample_num=100,\n",
    "                subgraph_building_method='zero_filling'):\n",
    "    if reward_method.lower() == 'gnn_score':\n",
    "        return partial(gnn_score,\n",
    "                       value_func=value_func,\n",
    "                       subgraph_building_method=subgraph_building_method)\n",
    "\n",
    "    elif reward_method.lower() == 'mc_shapley':\n",
    "        return partial(mc_shapley,\n",
    "                       value_func=value_func,\n",
    "                       subgraph_building_method=subgraph_building_method,\n",
    "                       sample_num=sample_num)\n",
    "\n",
    "    elif reward_method.lower() == 'l_shapley':\n",
    "        return partial(l_shapley,\n",
    "                       local_radius=local_radius,\n",
    "                       value_func=value_func,\n",
    "                       subgraph_building_method=subgraph_building_method)\n",
    "\n",
    "    elif reward_method.lower() == 'mc_l_shapley':\n",
    "        return partial(mc_l_shapley,\n",
    "                       local_radius=local_radius,\n",
    "                       value_func=value_func,\n",
    "                       subgraph_building_method=subgraph_building_method,\n",
    "                       sample_num=sample_num)\n",
    "\n",
    "    elif reward_method.lower() == 'nc_mc_l_shapley':\n",
    "        assert node_idx is not None, \" Wrong node idx input \"\n",
    "        return partial(NC_mc_l_shapley,\n",
    "                       node_idx=node_idx,\n",
    "                       local_radius=local_radius,\n",
    "                       value_func=value_func,\n",
    "                       subgraph_building_method=subgraph_building_method,\n",
    "                       sample_num=sample_num)\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "def k_hop_subgraph_with_default_whole_graph(\n",
    "        edge_index, node_idx=None, num_hops=3, relabel_nodes=False,\n",
    "        num_nodes=None, flow='source_to_target'):\n",
    "    r\"\"\"Computes the :math:`k`-hop subgraph of :obj:`edge_index` around node\n",
    "    :attr:`node_idx`.\n",
    "    It returns (1) the nodes involved in the subgraph, (2) the filtered\n",
    "    :obj:`edge_index` connectivity, (3) the mapping from node indices in\n",
    "    :obj:`node_idx` to their new location, and (4) the edge mask indicating\n",
    "    which edges were preserved.\n",
    "    Args:\n",
    "        node_idx (int, list, tuple or :obj:`torch.Tensor`): The central\n",
    "            node(s).\n",
    "        num_hops: (int): The number of hops :math:`k`.\n",
    "        edge_index (LongTensor): The edge indices.\n",
    "        relabel_nodes (bool, optional): If set to :obj:`True`, the resulting\n",
    "            :obj:`edge_index` will be relabeled to hold consecutive indices\n",
    "            starting from zero. (default: :obj:`False`)\n",
    "        num_nodes (int, optional): The number of nodes, *i.e.*\n",
    "            :obj:`max_val + 1` of :attr:`edge_index`. (default: :obj:`None`)\n",
    "        flow (string, optional): The flow direction of :math:`k`-hop\n",
    "            aggregation (:obj:`\"source_to_target\"` or\n",
    "            :obj:`\"target_to_source\"`). (default: :obj:`\"source_to_target\"`)\n",
    "    :rtype: (:class:`LongTensor`, :class:`LongTensor`, :class:`LongTensor`,\n",
    "             :class:`BoolTensor`)\n",
    "    \"\"\"\n",
    "\n",
    "    num_nodes = maybe_num_nodes(edge_index, num_nodes)\n",
    "\n",
    "    assert flow in ['source_to_target', 'target_to_source']\n",
    "    if flow == 'target_to_source':\n",
    "        row, col = edge_index\n",
    "    else:\n",
    "        col, row = edge_index  # edge_index 0 to 1, col: source, row: target\n",
    "\n",
    "    node_mask = row.new_empty(num_nodes, dtype=torch.bool)\n",
    "    edge_mask = row.new_empty(row.size(0), dtype=torch.bool)\n",
    "\n",
    "    inv = None\n",
    "\n",
    "    if node_idx is None:\n",
    "        subsets = torch.tensor([0])\n",
    "        cur_subsets = subsets\n",
    "        while 1:\n",
    "            node_mask.fill_(False)\n",
    "            node_mask[subsets] = True\n",
    "            torch.index_select(node_mask, 0, row, out=edge_mask)\n",
    "            subsets = torch.cat([subsets, col[edge_mask]]).unique()\n",
    "            if not cur_subsets.equal(subsets):\n",
    "                cur_subsets = subsets\n",
    "            else:\n",
    "                subset = subsets\n",
    "                break\n",
    "    else:\n",
    "        if isinstance(node_idx, (int, list, tuple)):\n",
    "            node_idx = torch.tensor([node_idx], device=row.device, dtype=torch.int64).flatten()\n",
    "        elif isinstance(node_idx, torch.Tensor) and len(node_idx.shape) == 0:\n",
    "            node_idx = torch.tensor([node_idx])\n",
    "        else:\n",
    "            node_idx = node_idx.to(row.device)\n",
    "\n",
    "        subsets = [node_idx]\n",
    "        for _ in range(num_hops):\n",
    "            node_mask.fill_(False)\n",
    "            node_mask[subsets[-1]] = True\n",
    "            torch.index_select(node_mask, 0, row, out=edge_mask)\n",
    "            subsets.append(col[edge_mask])\n",
    "        subset, inv = torch.cat(subsets).unique(return_inverse=True)\n",
    "        inv = inv[:node_idx.numel()]\n",
    "\n",
    "    node_mask.fill_(False)\n",
    "    node_mask[subset] = True\n",
    "    edge_mask = node_mask[row] & node_mask[col]\n",
    "\n",
    "    edge_index = edge_index[:, edge_mask]\n",
    "\n",
    "    if relabel_nodes:\n",
    "        node_idx = row.new_full((num_nodes,), -1)\n",
    "        node_idx[subset] = torch.arange(subset.size(0), device=row.device)\n",
    "        edge_index = node_idx[edge_index]\n",
    "\n",
    "    return subset, edge_index, inv, edge_mask  # subset: key new node idx; value original node idx\n",
    "\n",
    "\n",
    "def compute_scores(score_func, children):\n",
    "    results = []\n",
    "    for child in children:\n",
    "        if child.P == 0:\n",
    "            score = score_func(child.coalition, child.data)\n",
    "        else:\n",
    "            score = child.P\n",
    "        results.append(score)\n",
    "    return results\n",
    "\n",
    "\n",
    "class PlotUtils(object):\n",
    "    def __init__(self, dataset_name, is_show=True):\n",
    "        self.dataset_name = dataset_name\n",
    "        self.is_show = is_show\n",
    "\n",
    "    def plot(self, graph, nodelist, figname, title_sentence=None, **kwargs):\n",
    "        \"\"\" plot function for different dataset \"\"\"\n",
    "        if self.dataset_name.lower() in ['ba_2motifs', 'ba_lrp']:\n",
    "            self.plot_ba2motifs(graph, nodelist, title_sentence=title_sentence, figname=figname)\n",
    "        elif self.dataset_name.lower() in ['mutag'] + list(MoleculeNet.names.keys()):\n",
    "            x = kwargs.get('x')\n",
    "            self.plot_molecule(graph, nodelist, x, title_sentence=title_sentence, figname=figname)\n",
    "        elif self.dataset_name.lower() in ['ba_shapes', 'ba_community', 'tree_grid', 'tree_cycle']:\n",
    "            y = kwargs.get('y')\n",
    "            node_idx = kwargs.get('node_idx')\n",
    "            self.plot_bashapes(graph, nodelist, y, node_idx, title_sentence=title_sentence, figname=figname)\n",
    "        elif self.dataset_name.lower() in ['graph_sst2', 'graph_sst5', 'twitter']:\n",
    "            words = kwargs.get('words')\n",
    "            self.plot_sentence(graph, nodelist, words=words, title_sentence=title_sentence, figname=figname)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def plot_subgraph(self,\n",
    "                      graph,\n",
    "                      nodelist,\n",
    "                      colors: Union[None, str, List[str]] = '#FFA500',\n",
    "                      labels=None,\n",
    "                      edge_color='gray',\n",
    "                      edgelist=None,\n",
    "                      subgraph_edge_color='black',\n",
    "                      title_sentence=None,\n",
    "                      figname=None):\n",
    "\n",
    "        if edgelist is None:\n",
    "            edgelist = [(n_frm, n_to) for (n_frm, n_to) in graph.edges()\n",
    "                        if n_frm in nodelist and n_to in nodelist]\n",
    "        pos = nx.kamada_kawai_layout(graph)\n",
    "        pos_nodelist = {k: v for k, v in pos.items() if k in nodelist}\n",
    "\n",
    "        nx.draw_networkx_nodes(graph, pos,\n",
    "                               nodelist=list(graph.nodes()),\n",
    "                               node_color=colors,\n",
    "                               node_size=300)\n",
    "\n",
    "        nx.draw_networkx_edges(graph, pos, width=3, edge_color=edge_color, arrows=False)\n",
    "\n",
    "        nx.draw_networkx_edges(graph, pos=pos_nodelist,\n",
    "                               edgelist=edgelist, width=6,\n",
    "                               edge_color=subgraph_edge_color,\n",
    "                               arrows=False)\n",
    "\n",
    "        if labels is not None:\n",
    "            nx.draw_networkx_labels(graph, pos, labels)\n",
    "\n",
    "        plt.axis('off')\n",
    "        if figname is not None:\n",
    "            plt.savefig(figname)\n",
    "        if title_sentence is not None:\n",
    "            plt.title('\\n'.join(wrap(title_sentence, width=60)))\n",
    "        if self.is_show:\n",
    "            plt.show()\n",
    "        if figname is not None:\n",
    "            plt.close()\n",
    "\n",
    "    def plot_subgraph_with_nodes(self,\n",
    "                                 graph,\n",
    "                                 nodelist,\n",
    "                                 node_idx,\n",
    "                                 colors='#FFA500',\n",
    "                                 labels=None,\n",
    "                                 edge_color='gray',\n",
    "                                 edgelist=None,\n",
    "                                 subgraph_edge_color='black',\n",
    "                                 title_sentence=None,\n",
    "                                 figname=None):\n",
    "        node_idx = int(node_idx)\n",
    "        if edgelist is None:\n",
    "            edgelist = [(n_frm, n_to) for (n_frm, n_to) in graph.edges()\n",
    "                        if n_frm in nodelist and n_to in nodelist]\n",
    "\n",
    "        pos = nx.kamada_kawai_layout(graph)  # calculate according to graph.nodes()\n",
    "        pos_nodelist = {k: v for k, v in pos.items() if k in nodelist}\n",
    "\n",
    "        nx.draw_networkx_nodes(graph, pos,\n",
    "                               nodelist=list(graph.nodes()),\n",
    "                               node_color=colors,\n",
    "                               node_size=300)\n",
    "        if isinstance(colors, list):\n",
    "            list_indices = int(np.where(np.array(graph.nodes()) == node_idx)[0])\n",
    "            node_idx_color = colors[list_indices]\n",
    "        else:\n",
    "            node_idx_color = colors\n",
    "\n",
    "        nx.draw_networkx_nodes(graph, pos=pos,\n",
    "                               nodelist=[node_idx],\n",
    "                               node_color=node_idx_color,\n",
    "                               node_size=600)\n",
    "\n",
    "        nx.draw_networkx_edges(graph, pos, width=3, edge_color=edge_color, arrows=False)\n",
    "\n",
    "        nx.draw_networkx_edges(graph, pos=pos_nodelist,\n",
    "                               edgelist=edgelist, width=3,\n",
    "                               edge_color=subgraph_edge_color,\n",
    "                               arrows=False)\n",
    "\n",
    "        if labels is not None:\n",
    "            nx.draw_networkx_labels(graph, pos, labels)\n",
    "\n",
    "        plt.axis('off')\n",
    "        if title_sentence is not None:\n",
    "            plt.title('\\n'.join(wrap(title_sentence, width=60)))\n",
    "\n",
    "        if figname is not None:\n",
    "            plt.savefig(figname)\n",
    "        if self.is_show:\n",
    "            plt.show()\n",
    "        if figname is not None:\n",
    "            plt.close()\n",
    "\n",
    "    def plot_sentence(self, graph, nodelist, words, edgelist=None, title_sentence=None, figname=None):\n",
    "        pos = nx.kamada_kawai_layout(graph)\n",
    "        words_dict = {i: words[i] for i in graph.nodes}\n",
    "        if nodelist is not None:\n",
    "            pos_coalition = {k: v for k, v in pos.items() if k in nodelist}\n",
    "            nx.draw_networkx_nodes(graph, pos_coalition,\n",
    "                                   nodelist=nodelist,\n",
    "                                   node_color='yellow',\n",
    "                                   node_shape='o',\n",
    "                                   node_size=500)\n",
    "            if edgelist is None:\n",
    "                edgelist = [(n_frm, n_to) for (n_frm, n_to) in graph.edges()\n",
    "                            if n_frm in nodelist and n_to in nodelist]\n",
    "                nx.draw_networkx_edges(graph, pos=pos_coalition, edgelist=edgelist, width=5, edge_color='yellow')\n",
    "\n",
    "        nx.draw_networkx_nodes(graph, pos, nodelist=list(graph.nodes()), node_size=300)\n",
    "\n",
    "        nx.draw_networkx_edges(graph, pos, width=2, edge_color='grey')\n",
    "        nx.draw_networkx_labels(graph, pos, words_dict)\n",
    "\n",
    "        plt.axis('off')\n",
    "        plt.title('\\n'.join(wrap(' '.join(words), width=50)))\n",
    "        if title_sentence is not None:\n",
    "            string = '\\n'.join(wrap(' '.join(words), width=50))\n",
    "            string += '\\n'.join(wrap(title_sentence, width=60))\n",
    "            plt.title(string)\n",
    "        if figname is not None:\n",
    "            plt.savefig(figname)\n",
    "        if self.is_show:\n",
    "            plt.show()\n",
    "        if figname is not None:\n",
    "            plt.close()\n",
    "\n",
    "    def plot_bashapes(self,\n",
    "                      graph,\n",
    "                      nodelist,\n",
    "                      y,\n",
    "                      node_idx,\n",
    "                      edgelist=None,\n",
    "                      title_sentence=None,\n",
    "                      figname=None):\n",
    "        node_idxs = {k: int(v) for k, v in enumerate(y.reshape(-1).tolist())}\n",
    "        node_color = ['#FFA500', '#4970C6', '#FE0000', 'green']\n",
    "        colors = [node_color[v % len(node_color)] for k, v in node_idxs.items()]\n",
    "        self.plot_subgraph_with_nodes(graph,\n",
    "                                      nodelist,\n",
    "                                      node_idx,\n",
    "                                      colors,\n",
    "                                      edgelist=edgelist,\n",
    "                                      title_sentence=title_sentence,\n",
    "                                      figname=figname,\n",
    "                                      subgraph_edge_color='black')\n",
    "\n",
    "\n",
    "class MCTSNode(object):\n",
    "    def __init__(self, coalition: list = None, data: Data = None, ori_graph: nx.Graph = None,\n",
    "                 c_puct: float = 10.0, W: float = 0, N: int = 0, P: float = 0,\n",
    "                 load_dict: Optional[Dict] = None, device='cpu'):\n",
    "        self.data = data\n",
    "        self.coalition = coalition\n",
    "        self.ori_graph = ori_graph\n",
    "        self.device = device\n",
    "        self.c_puct = c_puct\n",
    "        self.children = []\n",
    "        self.W = W  # sum of node value\n",
    "        self.N = N  # times of arrival\n",
    "        self.P = P  # property score (reward)\n",
    "        if load_dict is not None:\n",
    "            self.load_info(load_dict)\n",
    "\n",
    "    def Q(self):\n",
    "        return self.W / self.N if self.N > 0 else 0\n",
    "\n",
    "    def U(self, n):\n",
    "        return self.c_puct * self.P * math.sqrt(n) / (1 + self.N)\n",
    "\n",
    "    @property\n",
    "    def info(self):\n",
    "        info_dict = {\n",
    "            'data': self.data.to('cpu'),\n",
    "            'coalition': self.coalition,\n",
    "            'ori_graph': self.ori_graph,\n",
    "            'W': self.W,\n",
    "            'N': self.N,\n",
    "            'P': self.P\n",
    "        }\n",
    "        return info_dict\n",
    "\n",
    "    def load_info(self, info_dict):\n",
    "        self.W = info_dict['W']\n",
    "        self.N = info_dict['N']\n",
    "        self.P = info_dict['P']\n",
    "        self.coalition = info_dict['coalition']\n",
    "        self.ori_graph = info_dict['ori_graph']\n",
    "        self.data = info_dict['data'].to(self.device)\n",
    "        self.children = []\n",
    "        return self\n",
    "\n",
    "\n",
    "class MCTS(object):\n",
    "    r\"\"\"\n",
    "    Monte Carlo Tree Search Method.\n",
    "    \n",
    "    Args:\n",
    "        X (:obj:`torch.Tensor`): Input node features\n",
    "        edge_index (:obj:`torch.Tensor`): The edge indices.\n",
    "        num_hops (:obj:`int`): The number of hops :math:`k`.\n",
    "        n_rollout (:obj:`int`): The number of sequence to build the monte carlo tree.\n",
    "        min_atoms (:obj:`int`): The number of atoms for the subgraph in the monte carlo tree leaf node.\n",
    "        c_puct (:obj:`float`): The hyper-parameter to encourage exploration while searching.\n",
    "        expand_atoms (:obj:`int`): The number of children to expand.\n",
    "        high2low (:obj:`bool`): Whether to expand children tree node from high degree nodes to low degree nodes.\n",
    "        node_idx (:obj:`int`): The target node index to extract the neighborhood.\n",
    "        score_func (:obj:`Callable`): The reward function for tree node, such as mc_shapely and mc_l_shapely.\n",
    "    \"\"\"\n",
    "    def __init__(self, X: torch.Tensor, edge_index: torch.Tensor, num_hops: int,\n",
    "                 n_rollout: int = 10, min_atoms: int = 3, c_puct: float = 10.0,\n",
    "                 expand_atoms: int = 14, high2low: bool = False,\n",
    "                 node_idx: int = None, score_func: Callable = None, device='cpu'):\n",
    "\n",
    "        self.X = X\n",
    "        self.edge_index = edge_index\n",
    "        self.device = device\n",
    "        self.num_hops = num_hops\n",
    "        self.data = Data(x=self.X, edge_index=self.edge_index)\n",
    "        graph_data = Data(x=self.X, edge_index=remove_self_loops(self.edge_index)[0])\n",
    "        self.graph = to_networkx(graph_data, to_undirected=True)\n",
    "        self.data = Batch.from_data_list([self.data])\n",
    "        self.num_nodes = self.graph.number_of_nodes()\n",
    "        self.score_func = score_func\n",
    "        self.n_rollout = n_rollout\n",
    "        self.min_atoms = min_atoms\n",
    "        self.c_puct = c_puct\n",
    "        self.expand_atoms = expand_atoms\n",
    "        self.high2low = high2low\n",
    "        self.new_node_idx = None\n",
    "\n",
    "        # extract the sub-graph and change the node indices.\n",
    "        if node_idx is not None:\n",
    "            self.ori_node_idx = node_idx\n",
    "            self.ori_graph = copy.copy(self.graph)\n",
    "            print(\"ori graph nodes\", self.graph.nodes())\n",
    "            x, edge_index, subset, edge_mask, kwargs = \\\n",
    "                self.__subgraph__(node_idx, self.X, self.edge_index, self.num_hops)\n",
    "            self.data = Batch.from_data_list([Data(x=x, edge_index=edge_index)])\n",
    "            self.graph = self.ori_graph.subgraph(subset.tolist())\n",
    "            mapping = {int(v): k for k, v in enumerate(subset)}\n",
    "            self.graph = nx.relabel_nodes(self.graph, mapping)\n",
    "            self.new_node_idx = torch.where(subset == self.ori_node_idx)[0].item()\n",
    "            self.num_nodes = self.graph.number_of_nodes()\n",
    "            self.subset = subset\n",
    "\n",
    "        self.root_coalition = sorted([node for node in range(self.num_nodes)])\n",
    "        self.MCTSNodeClass = partial(MCTSNode, data=self.data, ori_graph=self.graph,\n",
    "                                     c_puct=self.c_puct, device=self.device)\n",
    "        self.root = self.MCTSNodeClass(self.root_coalition)\n",
    "        self.state_map = {str(self.root.coalition): self.root}\n",
    "\n",
    "    def set_score_func(self, score_func):\n",
    "        self.score_func = score_func\n",
    "\n",
    "    @staticmethod\n",
    "    def __subgraph__(node_idx, x, edge_index, num_hops, **kwargs):\n",
    "        num_nodes, num_edges = x.size(0), edge_index.size(1)\n",
    "        subset, edge_index, _, edge_mask = k_hop_subgraph_with_default_whole_graph(\n",
    "            edge_index, node_idx, num_hops, relabel_nodes=True, num_nodes=num_nodes)\n",
    "\n",
    "        x = x[subset]\n",
    "        for key, item in kwargs.items():\n",
    "            if torch.is_tensor(item) and item.size(0) == num_nodes:\n",
    "                item = item[subset]\n",
    "            elif torch.is_tensor(item) and item.size(0) == num_edges:\n",
    "                item = item[edge_mask]\n",
    "            kwargs[key] = item\n",
    "\n",
    "        return x, edge_index, subset, edge_mask, kwargs\n",
    "\n",
    "    def mcts_rollout(self, tree_node):\n",
    "        cur_graph_coalition = tree_node.coalition\n",
    "        if len(cur_graph_coalition) <= self.min_atoms:\n",
    "            return tree_node.P\n",
    "\n",
    "        # Expand if this node has never been visited\n",
    "        if len(tree_node.children) == 0:\n",
    "            node_degree_list = list(self.graph.subgraph(cur_graph_coalition).degree)\n",
    "            node_degree_list = sorted(node_degree_list, key=lambda x: x[1], reverse=self.high2low)\n",
    "            all_nodes = [x[0] for x in node_degree_list]\n",
    "\n",
    "            if self.new_node_idx:\n",
    "                expand_nodes = [node for node in all_nodes if node != self.new_node_idx]\n",
    "            else:\n",
    "                expand_nodes = all_nodes\n",
    "\n",
    "            if len(all_nodes) > self.expand_atoms:\n",
    "                expand_nodes = expand_nodes[:self.expand_atoms]\n",
    "\n",
    "            for each_node in expand_nodes:\n",
    "                # for each node, pruning it and get the remaining sub-graph\n",
    "                # here we check the resulting sub-graphs and only keep the largest one\n",
    "                subgraph_coalition = [node for node in all_nodes if node != each_node]\n",
    "\n",
    "                subgraphs = [self.graph.subgraph(c)\n",
    "                             for c in nx.connected_components(self.graph.subgraph(subgraph_coalition))]\n",
    "\n",
    "                if self.new_node_idx:\n",
    "                    for sub in subgraphs:\n",
    "                        if self.new_node_idx in list(sub.nodes()):\n",
    "                            main_sub = sub\n",
    "                else:\n",
    "                    main_sub = subgraphs[0]\n",
    "\n",
    "                    for sub in subgraphs:\n",
    "                        if sub.number_of_nodes() > main_sub.number_of_nodes():\n",
    "                            main_sub = sub\n",
    "\n",
    "                new_graph_coalition = sorted(list(main_sub.nodes()))\n",
    "\n",
    "                # check the state map and merge the same sub-graph\n",
    "                find_same = False\n",
    "                for old_graph_node in self.state_map.values():\n",
    "                    if Counter(old_graph_node.coalition) == Counter(new_graph_coalition):\n",
    "                        new_node = old_graph_node\n",
    "                        find_same = True\n",
    "\n",
    "                if not find_same:\n",
    "                    new_node = self.MCTSNodeClass(new_graph_coalition)\n",
    "                    self.state_map[str(new_graph_coalition)] = new_node\n",
    "\n",
    "                find_same_child = False\n",
    "                for cur_child in tree_node.children:\n",
    "                    if Counter(cur_child.coalition) == Counter(new_graph_coalition):\n",
    "                        find_same_child = True\n",
    "\n",
    "                if not find_same_child:\n",
    "                    tree_node.children.append(new_node)\n",
    "\n",
    "            scores = compute_scores(self.score_func, tree_node.children)\n",
    "            for child, score in zip(tree_node.children, scores):\n",
    "                child.P = score\n",
    "\n",
    "        sum_count = sum([c.N for c in tree_node.children])\n",
    "        selected_node = max(tree_node.children, key=lambda x: x.Q() + x.U(sum_count))\n",
    "        v = self.mcts_rollout(selected_node)\n",
    "        selected_node.W += v\n",
    "        selected_node.N += 1\n",
    "        return v\n",
    "\n",
    "    def mcts(self, verbose=True):\n",
    "        if verbose:\n",
    "            print(f\"The nodes in graph is {self.graph.number_of_nodes()}\")\n",
    "        for rollout_idx in range(self.n_rollout):\n",
    "            self.mcts_rollout(self.root)\n",
    "            if verbose:\n",
    "                print(f\"At the {rollout_idx} rollout, {len(self.state_map)} states that have been explored.\")\n",
    "\n",
    "        explanations = [node for _, node in self.state_map.items()]\n",
    "        explanations = sorted(explanations, key=lambda x: x.P, reverse=True)\n",
    "        return explanations\n",
    "\n",
    "\n",
    "class SubgraphX(object):\n",
    "    r\"\"\"\n",
    "    The implementation of paper\n",
    "    `On Explainability of Graph Neural Networks via Subgraph Explorations <https://arxiv.org/abs/2102.05152>`_.\n",
    "    \n",
    "    Args:\n",
    "        model (:obj:`torch.nn.Module`): The target model prepared to explain\n",
    "        num_classes(:obj:`int`): Number of classes for the datasets\n",
    "        num_hops(:obj:`int`, :obj:`None`): The number of hops to extract neighborhood of target node\n",
    "          (default: :obj:`None`)\n",
    "        explain_graph(:obj:`bool`): Whether to explain graph classification model (default: :obj:`True`)\n",
    "        rollout(:obj:`int`): Number of iteration to get the prediction\n",
    "        min_atoms(:obj:`int`): Number of atoms of the leaf node in search tree\n",
    "        c_puct(:obj:`float`): The hyperparameter which encourages the exploration\n",
    "        expand_atoms(:obj:`int`): The number of atoms to expand\n",
    "          when extend the child nodes in the search tree\n",
    "        high2low(:obj:`bool`): Whether to expand children nodes from high degree to low degree when\n",
    "          extend the child nodes in the search tree (default: :obj:`False`)\n",
    "        local_radius(:obj:`int`): Number of local radius to calculate :obj:`l_shapley`, :obj:`mc_l_shapley`\n",
    "        sample_num(:obj:`int`): Sampling time of monte carlo sampling approximation for\n",
    "          :obj:`mc_shapley`, :obj:`mc_l_shapley` (default: :obj:`mc_l_shapley`)\n",
    "        reward_method(:obj:`str`): The command string to select the\n",
    "        subgraph_building_method(:obj:`str`): The command string for different subgraph building method,\n",
    "          such as :obj:`zero_filling`, :obj:`split` (default: :obj:`zero_filling`)\n",
    "        save_dir(:obj:`str`, :obj:`None`): Root directory to save the explanation results (default: :obj:`None`)\n",
    "        filename(:obj:`str`): The filename of results\n",
    "        vis(:obj:`bool`): Whether to show the visualization (default: :obj:`True`)\n",
    "    Example:\n",
    "        >>> # For graph classification task\n",
    "        >>> subgraphx = SubgraphX(model=model, num_classes=2)\n",
    "        >>> _, explanation_results, related_preds = subgraphx(x, edge_index)\n",
    "    \"\"\"\n",
    "    def __init__(self, model, num_classes: int, device, num_hops: Optional[int] = None, verbose: bool = False,\n",
    "                 explain_graph: bool = True, rollout: int = 20, min_atoms: int = 5, c_puct: float = 10.0,\n",
    "                 expand_atoms=14, high2low=False, local_radius=4, sample_num=100, reward_method='mc_l_shapley',\n",
    "                 subgraph_building_method='zero_filling', save_dir: Optional[str] = None,\n",
    "                 filename: str = 'example', vis: bool = True):\n",
    "\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        self.device = device\n",
    "        self.model.to(self.device)\n",
    "        self.num_classes = num_classes\n",
    "        self.num_hops = self.update_num_hops(num_hops)\n",
    "        self.explain_graph = explain_graph\n",
    "        self.verbose = verbose\n",
    "\n",
    "        # mcts hyper-parameters\n",
    "        self.rollout = rollout\n",
    "        self.min_atoms = min_atoms\n",
    "        self.c_puct = c_puct\n",
    "        self.expand_atoms = expand_atoms\n",
    "        self.high2low = high2low\n",
    "\n",
    "        # reward function hyper-parameters\n",
    "        self.local_radius = local_radius\n",
    "        self.sample_num = sample_num\n",
    "        self.reward_method = reward_method\n",
    "        self.subgraph_building_method = subgraph_building_method\n",
    "\n",
    "        # saving and visualization\n",
    "        self.vis = vis\n",
    "        self.save_dir = save_dir\n",
    "        self.filename = filename\n",
    "        self.save = True if self.save_dir is not None else False\n",
    "\n",
    "    def update_num_hops(self, num_hops):\n",
    "        if num_hops is not None:\n",
    "            return num_hops\n",
    "\n",
    "        k = 0\n",
    "        for module in self.model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                k += 1\n",
    "        return k\n",
    "\n",
    "    def get_reward_func(self, value_func, node_idx=None):\n",
    "        if self.explain_graph:\n",
    "            node_idx = None\n",
    "        else:\n",
    "            assert node_idx is not None\n",
    "        return reward_func(reward_method=self.reward_method,\n",
    "                           value_func=value_func,\n",
    "                           node_idx=node_idx,\n",
    "                           local_radius=self.local_radius,\n",
    "                           sample_num=self.sample_num,\n",
    "                           subgraph_building_method=self.subgraph_building_method)\n",
    "\n",
    "    def get_mcts_class(self, x, edge_index, node_idx: int = None, score_func: Callable = None):\n",
    "        if self.explain_graph:\n",
    "            node_idx = None\n",
    "        else:\n",
    "            assert node_idx is not None\n",
    "        return MCTS(x, edge_index,\n",
    "                    node_idx=node_idx,\n",
    "                    device=self.device,\n",
    "                    score_func=score_func,\n",
    "                    num_hops=self.num_hops,\n",
    "                    n_rollout=self.rollout,\n",
    "                    min_atoms=self.min_atoms,\n",
    "                    c_puct=self.c_puct,\n",
    "                    expand_atoms=self.expand_atoms,\n",
    "                    high2low=self.high2low)\n",
    "\n",
    "    def visualization(self, results: list,\n",
    "                      max_nodes: int, plot_utils: PlotUtils, words: Optional[list] = None,\n",
    "                      y: Optional[Tensor] = None, title_sentence: Optional[str] = None,\n",
    "                      vis_name: Optional[str] = None):\n",
    "        if self.save:\n",
    "            if vis_name is None:\n",
    "                vis_name = f\"{self.filename}.png\"\n",
    "        else:\n",
    "            vis_name = None\n",
    "        tree_node_x = find_closest_node_result(results, max_nodes=max_nodes)\n",
    "        if self.explain_graph:\n",
    "            if words is not None:\n",
    "                plot_utils.plot(tree_node_x.ori_graph,\n",
    "                                tree_node_x.coalition,\n",
    "                                words=words,\n",
    "                                title_sentence=title_sentence,\n",
    "                                figname=vis_name)\n",
    "            else:\n",
    "                plot_utils.plot(tree_node_x.ori_graph,\n",
    "                                tree_node_x.coalition,\n",
    "                                x=tree_node_x.data.x,\n",
    "                                title_sentence=title_sentence,\n",
    "                                figname=vis_name)\n",
    "        else:\n",
    "            subset = self.mcts_state_map.subset\n",
    "            subgraph_y = y[subset].to('cpu')\n",
    "            subgraph_y = torch.tensor([subgraph_y[node].item()\n",
    "                                       for node in tree_node_x.ori_graph.nodes()])\n",
    "            plot_utils.plot(tree_node_x.ori_graph,\n",
    "                            tree_node_x.coalition,\n",
    "                            node_idx=self.mcts_state_map.new_node_idx,\n",
    "                            title_sentence=title_sentence,\n",
    "                            y=subgraph_y,\n",
    "                            figname=vis_name)\n",
    "\n",
    "    def read_from_MCTSInfo_list(self, MCTSInfo_list):\n",
    "        if isinstance(MCTSInfo_list[0], dict):\n",
    "            ret_list = [MCTSNode(device=self.device).load_info(node_info) for node_info in MCTSInfo_list]\n",
    "        elif isinstance(MCTSInfo_list[0][0], dict):\n",
    "            ret_list = []\n",
    "            for single_label_MCTSInfo_list in MCTSInfo_list:\n",
    "                single_label_ret_list = [MCTSNode(device=self.device).load_info(node_info) for node_info in single_label_MCTSInfo_list]\n",
    "                ret_list.append(single_label_ret_list)\n",
    "        return ret_list\n",
    "\n",
    "    def write_from_MCTSNode_list(self, MCTSNode_list):\n",
    "        if isinstance(MCTSNode_list[0], MCTSNode):\n",
    "            ret_list = [node.info for node in MCTSNode_list]\n",
    "        elif isinstance(MCTSNode_list[0][0], MCTSNode):\n",
    "            ret_list = []\n",
    "            for single_label_MCTSNode_list in MCTSNode_list:\n",
    "                single_label_ret_list = [node.info for node in single_label_MCTSNode_list]\n",
    "                ret_list.append(single_label_ret_list)\n",
    "        return ret_list\n",
    "\n",
    "    def explain(self, x: Tensor, edge_index: Tensor, label: int,\n",
    "                max_nodes: int = 5,\n",
    "                node_idx: Optional[int] = None,\n",
    "                saved_MCTSInfo_list: Optional[List[List]] = None):\n",
    "        print(\"probs 0 \", self.model(x, edge_index))\n",
    "        print(\"probs 0 shape \", self.model(x, edge_index).shape)\n",
    "        print(\"probs 0 squeeze \", self.model(x, edge_index).squeeze().shape)\n",
    "        probs = self.model(x, edge_index).squeeze().softmax(dim=-1)\n",
    "        print(\"probs\", probs)\n",
    "        if self.explain_graph:\n",
    "            if saved_MCTSInfo_list:\n",
    "                results = self.read_from_MCTSInfo_list(saved_MCTSInfo_list)\n",
    "\n",
    "            if not saved_MCTSInfo_list:\n",
    "                value_func = GnnNetsGC2valueFunc(self.model, target_class=label)\n",
    "                payoff_func = self.get_reward_func(value_func)\n",
    "                self.mcts_state_map = self.get_mcts_class(x, edge_index, score_func=payoff_func)\n",
    "                results = self.mcts_state_map.mcts(verbose=self.verbose)\n",
    "\n",
    "            # l sharply score\n",
    "            value_func = GnnNetsGC2valueFunc(self.model, target_class=label)\n",
    "            tree_node_x = find_closest_node_result(results, max_nodes=max_nodes)\n",
    "\n",
    "        else:\n",
    "            if saved_MCTSInfo_list:\n",
    "                results = self.read_from_MCTSInfo_list(saved_MCTSInfo_list)\n",
    "\n",
    "            self.mcts_state_map = self.get_mcts_class(x, edge_index, node_idx=node_idx)\n",
    "            print(\"self.mcts_state_map\", self.mcts_state_map)\n",
    "            self.new_node_idx = self.mcts_state_map.new_node_idx\n",
    "            print(\"self.new_node_idx\", self.new_node_idx)\n",
    "            # mcts will extract the subgraph and relabel the nodes\n",
    "            value_func = GnnNetsNC2valueFunc(self.model,\n",
    "                                             node_idx=self.mcts_state_map.new_node_idx,\n",
    "                                             target_class=label)\n",
    "            print(\"value_func\", value_func)\n",
    "            if not saved_MCTSInfo_list:\n",
    "                payoff_func = self.get_reward_func(value_func,\n",
    "                                                   node_idx=self.mcts_state_map.new_node_idx)\n",
    "                self.mcts_state_map.set_score_func(payoff_func)\n",
    "                results = self.mcts_state_map.mcts(verbose=self.verbose)\n",
    "\n",
    "            tree_node_x = find_closest_node_result(results, max_nodes=max_nodes)\n",
    "            print(\"tree_node_x data\", tree_node_x.data.edge_index)\n",
    "            print(\"tree_node_x ori graph\", tree_node_x.ori_graph.nodes())\n",
    "            print(\"tree_node_x coalition\", tree_node_x.coalition)\n",
    "        # keep the important structure\n",
    "        masked_node_list = [node for node in range(tree_node_x.data.x.shape[0])\n",
    "                            if node in tree_node_x.coalition]\n",
    "\n",
    "        # remove the important structure, for node_classification,\n",
    "        # remain the node_idx when remove the important structure\n",
    "        maskout_node_list = [node for node in range(tree_node_x.data.x.shape[0])\n",
    "                             if node not in tree_node_x.coalition]\n",
    "        if not self.explain_graph:\n",
    "            maskout_node_list += [self.new_node_idx]\n",
    "\n",
    "        masked_score = gnn_score(masked_node_list,\n",
    "                                 tree_node_x.data,\n",
    "                                 value_func=value_func,\n",
    "                                 subgraph_building_method=self.subgraph_building_method)\n",
    "\n",
    "        maskout_score = gnn_score(maskout_node_list,\n",
    "                                  tree_node_x.data,\n",
    "                                  value_func=value_func,\n",
    "                                  subgraph_building_method=self.subgraph_building_method)\n",
    "\n",
    "        sparsity_score = sparsity(masked_node_list, tree_node_x.data,\n",
    "                                  subgraph_building_method=self.subgraph_building_method)\n",
    "\n",
    "        results = self.write_from_MCTSNode_list(results)\n",
    "        related_pred = {'masked': masked_score,\n",
    "                        'maskout': maskout_score,\n",
    "                        'origin': probs[node_idx, label].item(),\n",
    "                        'sparsity': sparsity_score}\n",
    "\n",
    "        return results, masked_node_list\n",
    "\n",
    "    def __call__(self, x: Tensor, edge_index: Tensor, **kwargs)\\\n",
    "            -> Tuple[None, List, List[Dict]]:\n",
    "        r\"\"\" explain the GNN behavior for the graph using SubgraphX method\n",
    "        Args:\n",
    "            x (:obj:`torch.Tensor`): Node feature matrix with shape\n",
    "              :obj:`[num_nodes, dim_node_feature]`\n",
    "            edge_index (:obj:`torch.Tensor`): Graph connectivity in COO format\n",
    "              with shape :obj:`[2, num_edges]`\n",
    "            kwargs(:obj:`Dict`):\n",
    "              The additional parameters\n",
    "                - node_idx (:obj:`int`, :obj:`None`): The target node index when explain node classification task\n",
    "                - max_nodes (:obj:`int`, :obj:`None`): The number of nodes in the final explanation results\n",
    "        :rtype: (:obj:`None`, List[torch.Tensor], List[Dict])\n",
    "        \"\"\"\n",
    "        node_idx = kwargs.get('node_idx')\n",
    "        max_nodes = kwargs.get('max_nodes')   # default max subgraph size\n",
    "\n",
    "        # collect all the class index\n",
    "        labels = tuple(label for label in range(self.num_classes))\n",
    "        ex_labels = tuple(torch.tensor([label]).to(self.device) for label in labels)\n",
    "\n",
    "        related_preds = []\n",
    "        explanation_results = []\n",
    "        saved_results = None\n",
    "        if self.save:\n",
    "            if os.path.isfile(os.path.join(self.save_dir, f\"{self.filename}.pt\")):\n",
    "                saved_results = torch.load(os.path.join(self.save_dir, f\"{self.filename}.pt\"))\n",
    "\n",
    "        for label_idx, label in enumerate(ex_labels):\n",
    "            results, related_pred = self.explain(x, edge_index,\n",
    "                                                 label=label,\n",
    "                                                 max_nodes=max_nodes,\n",
    "                                                 node_idx=node_idx,\n",
    "                                                 saved_MCTSInfo_list=saved_results)\n",
    "            related_preds.append(related_pred)\n",
    "            explanation_results.append(results)\n",
    "\n",
    "        if self.save:\n",
    "            torch.save(explanation_results,\n",
    "                       os.path.join(self.save_dir, f\"{self.filename}.pt\"))\n",
    "\n",
    "        return None, explanation_results, related_preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}